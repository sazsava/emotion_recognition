{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f031f5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sazsa\\anaconda3\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Библиотеки для работы с данными\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "#Для построения и работы с графиками\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#Для работы с моделями\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "#Для работы с изображениями\n",
    "import cv2\n",
    "from PIL import Image\n",
    "#Для работы с метрикой f1-score\n",
    "import tensorflow_addons as tfa\n",
    "f1 =tfa.metrics.F1Score(num_classes=9, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2b99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузим модели из чекпойнтов\n",
    "model_acc = tf.keras.models.load_model(\"D:/Skillbox/diploma_Ml_mid/checkpoints/emotion_recog/acc_2blocks.h5\", compile=False)\n",
    "model_f1 = tf.keras.models.load_model(\"D:/Skillbox/diploma_Ml_mid/checkpoints/emotion_recog/f1_2blocks.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fc35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим объект класса ImageDataGenerator (для подачи в модели):\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa809a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Названия классов:\n",
    "class_names = {0: 'anger',\n",
    "     1: 'contempt',\n",
    "     2: 'disgust',\n",
    "     3: 'fear',\n",
    "     4: 'happy',\n",
    "     5: 'neutral',\n",
    "     6: 'sad',\n",
    "     7: 'surprise',\n",
    "     8: 'uncertain'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec95cd6-8f36-4add-bd68-903f45b2ebd5",
   "metadata": {},
   "source": [
    "Попробуем всё объединить и проверить на работоспособность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac98275-0bfe-4d0e-a649-5f081db9c92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 507ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[EXIT] Camera stopped\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    required_size = (224, 224)\n",
    "\n",
    "    vid=cv2.VideoCapture(0)\n",
    "    vid.set(3, 448)  # Set width\n",
    "    vid.set(4, 224)  # Set height\n",
    "\n",
    "    if not (vid.isOpened()):\n",
    "        print(\"Could not open video device\")\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Разделяем видео на отдельные кадры-фреймы\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "\n",
    "        # инициализируем детектор\n",
    "        face_detector = cv2.FaceDetectorYN_create('D:/Skillbox/diploma_Ml_mid/data/YuNet/face_detection_yunet_2023mar.onnx',\n",
    "                          \"\", \n",
    "                          (640, 480),\n",
    "                          score_threshold=0.5)\n",
    "    \n",
    "        faces = face_detector.detect(frame)[1]\n",
    "    \n",
    "    \n",
    "        if faces is not None:\n",
    "            faces = faces.astype(int)\n",
    "            face = faces[0]\n",
    "            x1, y1, f_width, f_height = face[0], face[1], face[2], face[3]\n",
    "            x2, y2 = x1 + f_width, y1 + f_height\n",
    "\n",
    "\n",
    "            # Следим, чтобы бокс не вылез за пределы экрана, иначе функция вылетит с ошибкой:\n",
    "            if x2 > 640:\n",
    "                x2 = 640\n",
    "            if y2 > 480:\n",
    "                y2 = 480\n",
    "        \n",
    "        \n",
    "            # Нарисуем бокс вокруг лица\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "            # обрезка изображения до рамки лица для подачи в модель\n",
    "            face_boundary = frame[y1:y2, x1:x2]\n",
    "            face_boundary = Image.fromarray(face_boundary)\n",
    "    \n",
    "        \n",
    "            # Приведем к нужному размеру для подачи в модель     \n",
    "            face_image = face_boundary.resize(required_size)\n",
    "            face_array = np.asarray(face_image,'float32')\n",
    "            face_array = face_array[None, ...]\n",
    "            \n",
    "            \n",
    "            #Подаем в модель\n",
    "            test_generator = test_datagen.flow(face_array,\n",
    "                                       batch_size = 1,\n",
    "                                       seed =12,\n",
    "                                       shuffle  = False)\n",
    "\n",
    "            # Подставим в модели и сделаем предсказание\n",
    "            predict_result_acc = model_acc.predict(test_generator)\n",
    "            predict_result_f1 = model_f1.predict(test_generator)\n",
    "            model_predictions = np.array([predict_result_acc, predict_result_f1])\n",
    "            weights=[0.91803279, 0.08196721]\n",
    "            predictions = np.tensordot(model_predictions, weights, axes=((0),(0)))\n",
    "            pred = np.argmax(predictions)\n",
    "            pred_class = class_names[pred]\n",
    "        \n",
    "            #Проверка работоспособности\n",
    "            print(pred_class)\n",
    "            # Подписи класса\n",
    "            # шрифт\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # размер шрифта\n",
    "            fontScale = 0.6\n",
    "            # Толщина линии (пикселей)\n",
    "            thickness = 1\n",
    "            cv2.putText(frame, f'{pred_class}', (x1 + 5, y1 - 5), font, fontScale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "    \n",
    "        else:\n",
    "            print('No faces detected!')\n",
    "            cv2.putText(frame, 'No faces detected!', (50, 50), font, fontScale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        # Вывод результата\n",
    "        cv2.imshow('camera',frame)\n",
    "\n",
    "   \n",
    "        # Нажмите на 'q' чтобы выйти:\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "            print(\"[EXIT] Camera stopped\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    print(\"[EXIT] Camera stopped\")\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302f06a-984d-4a2f-8c53-9e090f37f72e",
   "metadata": {},
   "source": [
    "В задании к работе четко указано, что модель необходимо обернуть в Python-класс с определенным набором методов. Единственное, что не совсем понятно: весь ли код должен быть обернут в класс или только непосредственная часть для предсказания (загрузка весов предобученной модели распознавания эмоций, собственно предсказание по изображению и его, предсказания, вывод). Попробуем имплементировать всё. Для начала создадим более узкий класс для предсказания. Назовем его EmoRecog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188d9354-4ca7-4086-91a2-13158377fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoRecog():\n",
    "    # Названия классов:\n",
    "    em_names = {0: 'anger',\n",
    "         1: 'contempt',\n",
    "         2: 'disgust',\n",
    "         3: 'fear',\n",
    "         4: 'happy',\n",
    "         5: 'neutral',\n",
    "         6: 'sad',\n",
    "         7: 'surprise',\n",
    "         8: 'uncertain'}\n",
    "    \n",
    "    def __init__(self):\n",
    "         self.model_acc = tf.keras.models.load_model(\"D:/Skillbox/diploma_Ml_mid/checkpoints/emotion_recog/acc_2blocks.h5\", compile=False)\n",
    "         self.model_f1 = tf.keras.models.load_model(\"D:/Skillbox/diploma_Ml_mid/checkpoints/emotion_recog/f1_2blocks.h5\", compile=False)\n",
    "         #Создадим объект класса ImageDataGenerator (для подачи в модели):\n",
    "         self.test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "    def predict(self, img):\n",
    "        #Подаем в модель\n",
    "        test_generator = self.test_datagen.flow(img, batch_size = 1, seed =12, shuffle  = False)\n",
    "        #Получаем предсказания:\n",
    "        acc_preds = self.model_acc.predict(test_generator)\n",
    "        f1_preds = self.model_f1.predict(test_generator)\n",
    "        model_preds = np.array([acc_preds, f1_preds])\n",
    "        model_preds = np.tensordot(model_preds, [0.91803279, 0.08196721], axes=((0),(0)))\n",
    "        model_preds = EmoRecog.em_names[np.argmax(model_preds)]\n",
    "        return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9f602d-5753-461c-9f15-b92453ab0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # инициализируем детектор\n",
    "face_detector = cv2.FaceDetectorYN_create('D:/Skillbox/diploma_Ml_mid/data/YuNet/face_detection_yunet_2023mar.onnx',\n",
    "                          \"\", \n",
    "                          # (im_width, im_height),\n",
    "                          (640, 480),                \n",
    "                          score_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e73ca-a5fd-411e-a348-34646eed3726",
   "metadata": {},
   "source": [
    "Проверка работоспособности данного набора кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e5a775-2807-4760-aac9-08c79f753cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "anger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function UniquePtr.__del__ at 0x00000242A47A8360>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sazsa\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 71, in __del__\n",
      "    obj = self._obj\n",
      "          ^^^^^^^^^\n",
      "AttributeError: 'ScopedTFGraph' object has no attribute '_obj'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXIT] Camera stopped\n"
     ]
    }
   ],
   "source": [
    "rec_model = EmoRecog()\n",
    "\n",
    "try:\n",
    "    required_size = (224, 224)\n",
    "    vid=cv2.VideoCapture(0)\n",
    "    vid.set(3, 448)  # Set width\n",
    "    vid.set(4, 224)  # Set height\n",
    "\n",
    "    if not (vid.isOpened()):\n",
    "        print(\"Could not open video device\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Разделяем видео на отдельные кадры-фреймы\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "\n",
    "        faces = face_detector.detect(frame)[1]\n",
    "    \n",
    "    \n",
    "        if faces is not None:\n",
    "            faces = faces.astype(int)\n",
    "            face = faces[0]\n",
    "            x1, y1, f_width, f_height = face[0], face[1], face[2], face[3]\n",
    "            x2, y2 = x1 + f_width, y1 + f_height\n",
    "\n",
    "\n",
    "            # Следим, чтобы бокс не вылез за пределы экрана, иначе функция вылетит с ошибкой:\n",
    "            if x2 > 640:\n",
    "                x2 = 640\n",
    "            if y2 > 480:\n",
    "                y2 = 480\n",
    "        \n",
    "            # Нарисуем бокс вокруг лица\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "            # обрезка изображения до рамки лица для подачи в модель\n",
    "            face_boundary = frame[y1:y2, x1:x2]\n",
    "            face_boundary = Image.fromarray(face_boundary)\n",
    "\n",
    "           \n",
    "            # Приведем к нужному размеру для подачи в модель     \n",
    "            face_image = face_boundary.resize(required_size)\n",
    "            face_array = np.asarray(face_image,'float32')\n",
    "            face_array = face_array[None, ...]\n",
    "            \n",
    "            \n",
    "            # #Подаем в модель\n",
    "\n",
    "            pred_class = rec_model.predict(face_array)\n",
    "            #Проверка работоспособности\n",
    "            print(pred_class)\n",
    "            # Подписи класса\n",
    "            # шрифт\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # размер шрифта\n",
    "            fontScale = 0.6\n",
    "            # Толщина линии (пикселей)\n",
    "            thickness = 1\n",
    "            cv2.putText(frame, f'{pred_class}', (x1 + 5, y1 - 5), font, fontScale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "    \n",
    "        else:\n",
    "            print('No faces detected!')\n",
    "            cv2.putText(frame, 'No faces detected!', (50, 50), font, fontScale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        # Вывод результата\n",
    "        cv2.imshow('camera',frame)\n",
    "\n",
    "   \n",
    "        # Нажмите на 'q' чтобы выйти:\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "            print(\"[EXIT] Camera stopped\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    print(\"[EXIT] Camera stopped\")\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b4ce2e-27c7-4511-acf2-602335881487",
   "metadata": {},
   "source": [
    "А вот теперь напишем класс, который охватывает практически всё оставшееся от разделения изображения на кадры до вывода предсказаний на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e907cce9-f16f-4c2d-91fb-1d15e35b9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDisplay():\n",
    "    #Шрифт\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #Размер шрифта\n",
    "    fontScale = 0.6\n",
    "    # Толщина линии (пикселей)\n",
    "    thickness = 1\n",
    "    #Цвет (зеленый)\n",
    "    font_color = (0, 255, 0)\n",
    "    #Параметры фрейма:\n",
    "    xmax=640 \n",
    "    ymax=480\n",
    "    #Для изменения размеров далее\n",
    "    required_size = (224, 224)\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vid = cv2.VideoCapture(0)\n",
    "        self.vid.set(3, 448)  # установка ширины дисплея\n",
    "        self.vid.set(4, 224)  # установка высоты дисплея\n",
    "        #Проверка подключения камеры:\n",
    "        if not (self.vid.isOpened()):\n",
    "            print(\"Could not open video device\")\n",
    "        self.face_detection_model = cv2.FaceDetectorYN_create('D:/Skillbox/diploma_Ml_mid/data/YuNet/face_detection_yunet_2023mar.onnx',\n",
    "                          \"\", \n",
    "                          (self.xmax, self.ymax),                \n",
    "                          score_threshold=0.5)\n",
    "\n",
    "    def __del__(self):\n",
    "        # Отсановим камеру и выведем сообщение об остановке\n",
    "        self.vid.release()\n",
    "        print(\"[EXIT] Camera stopped\")\n",
    "\n",
    "    def putText (self, frame, text, x,y):\n",
    "        cv2.putText(frame, text, (x, y), self.font, self.fontScale, self.font_color, self.thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('camera', frame)\n",
    "\n",
    "    def noface_error(self):\n",
    "        #Если лица не находятся, выводим сообщение на кадр:\n",
    "        #Напечатаем текст для проверки\n",
    "        print('No faces detected!')\n",
    "        self.putText('No faces detected!', 50, 50)\n",
    "\n",
    "    def face_to_array(self, frame, face_boundary):\n",
    "        face_boundary = Image.fromarray(face_boundary)\n",
    "        face_image = face_boundary.resize(self.required_size)\n",
    "        face_array = np.asarray(face_image,'float32')\n",
    "        face_array = face_array[None, ...]\n",
    "        return face_array\n",
    "        \n",
    "\n",
    "    def pred_emotion(self, model):\n",
    "        # Разделяем видео на отдельные кадры-фреймы\n",
    "        ret, frame = self.vid.read()\n",
    "        #Находим лица\n",
    "        faces = self.face_detection_model.detect(frame)[1]\n",
    "\n",
    "\n",
    "        if faces is not None:\n",
    "            faces = faces.astype(int)\n",
    "            face = faces[0]\n",
    "            x1, y1, f_width, f_height = face[0], face[1], face[2], face[3]\n",
    "            x2, y2 = x1 + f_width, y1 + f_height\n",
    "\n",
    "\n",
    "            # Следим, чтобы бокс не вылез за пределы экрана, иначе функция вылетит с ошибкой:\n",
    "            if x2 > self.xmax:\n",
    "                x2 = self.xmax\n",
    "            if y2 > self.ymax:\n",
    "                y2 = self.ymax\n",
    "        \n",
    "            # Нарисуем бокс вокруг лица\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            face_boundary = frame[y1:y2, x1:x2]\n",
    "            # обрезка изображения до рамки лица для подачи в модель\n",
    "            face_array = self.face_to_array(frame, face_boundary)\n",
    "\n",
    "             # Подаем в модель\n",
    "            pred_class = model.predict(face_array)\n",
    "            #Проверка работоспособности\n",
    "            print(pred_class)\n",
    "            self.putText(frame, f'{pred_class}', x1 + 5, y1 - 5)\n",
    "        \n",
    "        else:\n",
    "            print('No faces detected!')\n",
    "            self.putText(frame, 'No faces detected!',50, 50)\n",
    "        \n",
    "        return cv2.imshow('camera',frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb20e7-87b1-41bd-a3a3-a6002c0fdb58",
   "metadata": {},
   "source": [
    "Итоговая проверка кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ca5788-ab53-4594-a6f9-01ac8a0bb0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "sad\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "[EXIT] Camera stopped\n"
     ]
    }
   ],
   "source": [
    "rec_model = EmoRecog()\n",
    "\n",
    "try:\n",
    "\n",
    "    disp = VideoDisplay()\n",
    "\n",
    "    while True:\n",
    "        disp.pred_emotion(rec_model)\n",
    "        # Нажмите на 'q' чтобы выйти:\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "            print(\"[EXIT] Camera stopped\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    #Остановка камеры:\n",
    "    del disp\n",
    "    \n",
    "#Закрытие всех окон:\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc291037-c5e5-46ce-9ebb-944c2c946e31",
   "metadata": {},
   "source": [
    "Замечательно, похоже, что всё работает и очевидных ошибок и вылетов кода нет. Камера успешно инициируется и закрывается по завершению работы. Модель предсказания эмоций так же не ругается и не вылетает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07326570-f5e3-4751-bc56-31186e0d83f0",
   "metadata": {},
   "source": [
    "Попробуем сделать так, чтобы наш класс мог обработать сразу несколько лиц на кадре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d606bb0b-d52b-4653-be2a-bf6b3826376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDisplay():\n",
    "    #Шрифт\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #Размер шрифта\n",
    "    fontScale = 0.6\n",
    "    # Толщина линии (пикселей)\n",
    "    thickness = 1\n",
    "    #Цвет (зеленый)\n",
    "    font_color = (0, 255, 0)\n",
    "    #Параметры фрейма:\n",
    "    xmax=640 \n",
    "    ymax=480\n",
    "    #Для изменения размеров далее\n",
    "    required_size = (224, 224)\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vid = cv2.VideoCapture(0)\n",
    "        self.vid.set(3, 448)  # установка ширины дисплея\n",
    "        self.vid.set(4, 224)  # установка высоты дисплея\n",
    "        #Проверка подключения камеры:\n",
    "        if not (self.vid.isOpened()):\n",
    "            print(\"Could not open video device\")\n",
    "        self.face_detection_model = cv2.FaceDetectorYN_create('D:/Skillbox/diploma_Ml_mid/data/YuNet/face_detection_yunet_2023mar.onnx',\n",
    "                          \"\", \n",
    "                          (self.xmax, self.ymax),                \n",
    "                          score_threshold=0.5)\n",
    "\n",
    "    def __del__(self):\n",
    "        # Отсановим камеру и выведем сообщение об остановке\n",
    "        self.vid.release()\n",
    "        print(\"[EXIT] Camera stopped\")\n",
    "\n",
    "    def putText (self, frame, text, x,y):\n",
    "        cv2.putText(frame, text, (x, y), self.font, self.fontScale, self.font_color, self.thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('camera', frame)\n",
    "\n",
    "    def noface_error(self):\n",
    "        #Если лица не находятся, выводим сообщение на кадр:\n",
    "        #Напечатаем текст для проверки\n",
    "        print('No faces detected!')\n",
    "        self.putText('No faces detected!', 50, 50)\n",
    "\n",
    "    def face_to_array(self, frame, face_boundary):\n",
    "        face_boundary = Image.fromarray(face_boundary)\n",
    "        face_image = face_boundary.resize(self.required_size)\n",
    "        face_array = np.asarray(face_image,'float32')\n",
    "        face_array = face_array[None, ...]\n",
    "        return face_array\n",
    "        \n",
    "\n",
    "    def pred_emotion(self, model):\n",
    "        # Разделяем видео на отдельные кадры-фреймы\n",
    "        ret, frame = self.vid.read()\n",
    "        #Находим лица\n",
    "        faces = self.face_detection_model.detect(frame)[1]\n",
    "\n",
    "\n",
    "        if faces is not None:\n",
    "            for face in faces:\n",
    "                face = face.astype(int)\n",
    "                x1, y1, f_width, f_height = face[0], face[1], face[2], face[3]\n",
    "                x2, y2 = x1 + f_width, y1 + f_height\n",
    "\n",
    "\n",
    "                # Следим, чтобы бокс не вылез за пределы экрана, иначе функция вылетит с ошибкой:\n",
    "                if x2 > self.xmax:\n",
    "                    x2 = self.xmax\n",
    "                if y2 > self.ymax:\n",
    "                    y2 = self.ymax\n",
    "        \n",
    "                # Нарисуем бокс вокруг лица\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                face_boundary = frame[y1:y2, x1:x2]\n",
    "                # обрезка изображения до рамки лица для подачи в модель\n",
    "                face_array = self.face_to_array(frame, face_boundary)\n",
    "\n",
    "                 # Подаем в модель\n",
    "                pred_class = model.predict(face_array)\n",
    "                #Проверка работоспособности\n",
    "                print(pred_class)\n",
    "                self.putText(frame, f'{pred_class}', x1 + 5, y1 - 5)\n",
    "        \n",
    "        else:\n",
    "            print('No faces detected!')\n",
    "            self.putText(frame, 'No faces detected!',50, 50)\n",
    "        \n",
    "        return cv2.imshow('camera',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63cac944-c553-4490-bfee-b59b5b36c3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 499ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "uncertain\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "uncertain\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "surprise\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "happy\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "uncertain\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "surprise\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "sad\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "neutral\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "fear\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "uncertain\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "anger\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "anger\n",
      "[EXIT] Camera stopped\n"
     ]
    }
   ],
   "source": [
    "rec_model = EmoRecog()\n",
    "\n",
    "try:\n",
    "\n",
    "    disp = VideoDisplay()\n",
    "\n",
    "    while True:\n",
    "        disp.pred_emotion(rec_model)\n",
    "        # Нажмите на 'q' чтобы выйти:\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "            print(\"[EXIT] Camera stopped\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    #Остановка камеры:\n",
    "    del disp\n",
    "    \n",
    "#Закрытие всех окон:\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a189dd-af8e-4f39-bcb1-8b160c2e81d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
